import os
import logging
from pathlib import Path
from typing import Dict, Any, Optional, List, Union, Iterator
import json
import time
import httplib2
import asyncio

from google import genai
from google.genai import types
from utils.config import config_manager

logger = logging.getLogger(__name__)

# ãƒ‡ãƒ•ã‚©ãƒ«ãƒˆã®ãƒ¢ãƒ‡ãƒ«è¨­å®š (ç’°å¢ƒã¾ãŸã¯è¨­å®šæœªæŒ‡å®šæ™‚ã®ãƒ•ã‚©ãƒ¼ãƒ«ãƒãƒƒã‚¯)
DEFAULT_TRANSCRIPTION_MODEL = config_manager.get_model("gemini_transcription") or "gemini-2.0-flash-001"
DEFAULT_MINUTES_MODEL = config_manager.get_model("gemini_minutes") or "gemini-2.0-flash-001"
DEFAULT_TITLE_MODEL = config_manager.get_model("gemini_title") or "gemini-2.0-flash-001"

MAX_RETRIES = 3
RETRY_DELAY = 5  # ç§’
MAX_FILE_SIZE_MB = 100  # ãƒ‡ãƒ•ã‚©ãƒ«ãƒˆã®æœ€å¤§ãƒ•ã‚¡ã‚¤ãƒ«ã‚µã‚¤ã‚ºï¼ˆMBï¼‰
MAX_FILE_WAIT_RETRIES = 30  # ãƒ•ã‚¡ã‚¤ãƒ«å‡¦ç†å¾…æ©Ÿã®æœ€å¤§ãƒªãƒˆãƒ©ã‚¤å›æ•°
FILE_WAIT_RETRY_DELAY = 5  # ãƒ•ã‚¡ã‚¤ãƒ«å‡¦ç†å¾…æ©Ÿã®é–“éš”ï¼ˆç§’ï¼‰

class MediaType:
    """ã‚µãƒãƒ¼ãƒˆã•ã‚Œã‚‹ãƒ¡ãƒ‡ã‚£ã‚¢ã‚¿ã‚¤ãƒ—ã®å®šæ•°"""
    AUDIO = "audio"
    VIDEO = "video"
    IMAGE = "image"

class GeminiAPIError(Exception):
    """Gemini APIå‡¦ç†ä¸­ã®ã‚¨ãƒ©ãƒ¼ã‚’è¡¨ã™ã‚«ã‚¹ã‚¿ãƒ ä¾‹å¤–"""
    pass

# äº’æ›æ€§ã®ãŸã‚ã«æ—¢å­˜ã®ä¾‹å¤–ã‚¯ãƒ©ã‚¹åã‚‚ä¿æŒ
TranscriptionError = GeminiAPIError

class VideoFileTooLargeError(GeminiAPIError):
    """å‹•ç”»ãƒ•ã‚¡ã‚¤ãƒ«ã‚µã‚¤ã‚ºãŒå¤§ãã™ãã‚‹å ´åˆã®ã‚¨ãƒ©ãƒ¼"""
    pass

class GeminiAPI:
    """Gemini APIã‚¯ãƒ©ã‚¤ã‚¢ãƒ³ãƒˆ"""
    
    def __init__(
        self,
        transcription_model: str = None,
        minutes_model: str = None,
        title_model: str = None,
        max_file_size_mb: int = None,
        api_key: str = None
    ):
        """Gemini APIã‚¯ãƒ©ã‚¤ã‚¢ãƒ³ãƒˆã‚’åˆæœŸåŒ–
        
        Args:
            transcription_model (str, optional): æ›¸ãèµ·ã“ã—ç”¨ã®ãƒ¢ãƒ‡ãƒ«å
            minutes_model (str, optional): è­°äº‹éŒ²ã¾ã¨ã‚ç”¨ã®ãƒ¢ãƒ‡ãƒ«å
            title_model (str, optional): ã‚¿ã‚¤ãƒˆãƒ«ç”Ÿæˆç”¨ã®ãƒ¢ãƒ‡ãƒ«å
            max_file_size_mb (int, optional): æœ€å¤§ãƒ•ã‚¡ã‚¤ãƒ«ã‚µã‚¤ã‚ºï¼ˆMBï¼‰
            api_key (str, optional): ç›´æ¥æŒ‡å®šã™ã‚‹APIã‚­ãƒ¼
        """
        # SSLè¨¼æ˜æ›¸ã®è¨­å®šï¼ˆäº’æ›æ€§ã®ãŸã‚ï¼‰
        cert_path = os.environ.get('SSL_CERT_FILE')
        if cert_path:
            httplib2.CA_CERTS = cert_path
            logger.info(f"SSLè¨¼æ˜æ›¸ãŒè¨­å®šã•ã‚Œã¾ã—ãŸ: {cert_path}")
            
        # è¨­å®šã®èª­ã¿è¾¼ã¿
        config = config_manager.get_config()
        
        # APIã‚­ãƒ¼ã‚’å–å¾—ï¼ˆå„ªå…ˆé †ä½: å¼•æ•° > ç’°å¢ƒå¤‰æ•° > è¨­å®šãƒ•ã‚¡ã‚¤ãƒ«ï¼‰
        self.api_key = api_key or os.getenv("GEMINI_API_KEY") or os.getenv("GOOGLE_API_KEY") or config.get('gemini_api_key')
        
        if not self.api_key:
            error_msg = "Gemini API keyãŒè¨­å®šã•ã‚Œã¦ã„ã¾ã›ã‚“ã€‚ç’°å¢ƒå¤‰æ•°GEMINI_API_KEYã€GOOGLE_API_KEYã€ã¾ãŸã¯è¨­å®šãƒ•ã‚¡ã‚¤ãƒ«ã®gemini_api_keyã‚’è¨­å®šã—ã¦ãã ã•ã„ã€‚"
            logger.error(error_msg)
            raise GeminiAPIError(error_msg)
        
        # ãƒ¢ãƒ‡ãƒ«åã®è¨­å®šï¼ˆå¼•æ•° â†’ è¨­å®šãƒ•ã‚¡ã‚¤ãƒ« â†’ ãƒ‡ãƒ•ã‚©ãƒ«ãƒˆå€¤ã®å„ªå…ˆé †ï¼‰
        self.transcription_model = transcription_model or config.get('models', {}).get('gemini_transcription', DEFAULT_TRANSCRIPTION_MODEL)
        self.minutes_model = minutes_model or config.get('models', {}).get('gemini_minutes', DEFAULT_MINUTES_MODEL)
        self.title_model = title_model or config.get('models', {}).get('gemini_title', DEFAULT_TITLE_MODEL)
        
        # æœ€å¤§ãƒ•ã‚¡ã‚¤ãƒ«ã‚µã‚¤ã‚ºã®è¨­å®š
        self.max_file_size_mb = max_file_size_mb or config.get('max_file_size_mb', MAX_FILE_SIZE_MB)
        
        # ã‚¯ãƒ©ã‚¤ã‚¢ãƒ³ãƒˆã®åˆæœŸåŒ– - Gemini API æ–°ã—ã„ã‚¹ã‚¿ã‚¤ãƒ«
        # APIãƒãƒ¼ã‚¸ãƒ§ãƒ³ã‚’v1alphaã«è¨­å®š
        self.client = genai.Client(
            api_key=self.api_key,
            http_options={'api_version': 'v1alpha'}
        )
        
        # äº’æ›æ€§ã®ãŸã‚ã®è¨­å®š
        self.generation_config = {
            "temperature": 0.1,
            "top_p": 0.95,
            "top_k": 40,
            "max_output_tokens": 8192,
            "response_mime_type": "application/json",
        }
        
        # ã‚¿ã‚¤ãƒˆãƒ«ç”Ÿæˆç”¨ã®è¨­å®š
        self.title_generation_config = {
            "temperature": 1.0,
            "top_p": 0.95,
            "top_k": 40,
            "max_output_tokens": 100,
            "response_mime_type": "application/json",
        }
        
        # è­°äº‹éŒ²ç”Ÿæˆç”¨ã®è¨­å®š
        self.minutes_generation_config = {
            "temperature": 1.0,
            "top_p": 0.95,
            "top_k": 64,
            "max_output_tokens": 8192,
            "response_mime_type": "text/plain",
        }
        
        # ç”»åƒè§£æç”¨ã®è¨­å®š
        self.image_analysis_config = {
            "temperature": 0.7,
            "top_p": 0.95,
            "top_k": 40,
            "max_output_tokens": 4096,
            "response_mime_type": "text/plain",
        }
        
        # å‹•ç”»è§£æç”¨ã®è¨­å®š
        self.video_analysis_config = {
            "temperature": 0.7,
            "top_p": 0.95,
            "top_k": 40,
            "max_output_tokens": 8192,
            "response_mime_type": "text/plain",
        }
        
        # ã‚·ã‚¹ãƒ†ãƒ ãƒ—ãƒ­ãƒ³ãƒ—ãƒˆï¼ˆäº’æ›æ€§ã®ãŸã‚ï¼‰
        self.system_prompt = """ã‚ãªãŸã¯ä¼šè­°ã®æ›¸ãèµ·ã“ã—ã‚’è¡Œã†å°‚é–€å®¶ã§ã™ã€‚
    ä»¥ä¸‹ã®ç‚¹ã«æ³¨æ„ã—ã¦ã€éŸ³å£°ãƒ•ã‚¡ã‚¤ãƒ«ã«å¿ å®Ÿãªæ›¸ãèµ·ã“ã—ãƒ†ã‚­ã‚¹ãƒˆã‚’ä½œæˆã—ã¦ãã ã•ã„ï¼š
    1. ä¸ãˆã‚‰ã‚ŒãŸãƒ“ãƒ‡ã‚ªã‹ã‚‰ç™ºè¨€è€…ã‚’ç‰¹å®šã™ã‚‹
    2. ç™ºè¨€è€…ã¨ç™ºè¨€å†…å®¹ã‚’åˆ†ã‘ã¦è¡¨ç¤º
    3. ç™ºè¨€ã®æ•´å½¢ã¯æœ€å°é™ã«ã¨ã©ã‚ã€ç™ºè¨€ã‚’ãã®ã¾ã¾æ›¸ãèµ·ã“ã™
    4. ä»¥ä¸‹ã®JSONå½¢å¼ã§å‡ºåŠ›ï¼š
    {
      "conversations": [
        {
          "speaker": "ç™ºè¨€è€…å",
          "utterance": "ç™ºè¨€å†…å®¹"
        },
        ...
      ]
    }
    
    å…¥åŠ›ã•ã‚ŒãŸéŸ³å£°ã®æ›¸ãèµ·ã“ã—ãƒ†ã‚­ã‚¹ãƒˆã‚’ä¸Šè¨˜ã®å½¢å¼ã«å¤‰æ›ã—ã¦ãã ã•ã„ã€‚ ã€‚"""
        
        # ã‚¿ã‚¤ãƒˆãƒ«ç”Ÿæˆç”¨ã®ã‚·ã‚¹ãƒ†ãƒ ãƒ—ãƒ­ãƒ³ãƒ—ãƒˆ
        self.title_system_prompt = """ä¼šè­°ã®æ›¸ãèµ·ã“ã—ã‹ã‚‰ã“ã®ä¼šè­°ã®ãƒ¡ã‚¤ãƒ³ã¨ãªã‚‹è­°é¡ŒãŒä½•ã ã£ãŸã®ã‹ã‚’æ•™ãˆã¦ã€‚ä¾‹ï¼šå–å¼•å…ˆã¨ã‚«ãƒ•ã‚§ã®æ–¹å‘æ€§ã«é–¢ã™ã‚‹ä¼šè­°"""
        
        logger.info(f"GeminiAPI initialized - PromptCreate Model: {self.transcription_model}")
        logger.info(f"Process model: {self.minutes_model}, Title model: {self.title_model}")
        logger.info(f"Max file size: {self.max_file_size_mb} MB")

    def _check_file_size(self, file_path: str) -> None:
        """ãƒ•ã‚¡ã‚¤ãƒ«ã‚µã‚¤ã‚ºã‚’ãƒã‚§ãƒƒã‚¯ã—ã€å¤§ãã™ãã‚‹å ´åˆã¯ä¾‹å¤–ã‚’ç™ºç”Ÿ
        
        Args:
            file_path (str): ãƒã‚§ãƒƒã‚¯ã™ã‚‹ãƒ•ã‚¡ã‚¤ãƒ«ã®ãƒ‘ã‚¹
            
        Raises:
            VideoFileTooLargeError: ãƒ•ã‚¡ã‚¤ãƒ«ã‚µã‚¤ã‚ºãŒåˆ¶é™ã‚’è¶…ãˆã¦ã„ã‚‹å ´åˆ
            FileNotFoundError: ãƒ•ã‚¡ã‚¤ãƒ«ãŒå­˜åœ¨ã—ãªã„å ´åˆ
        """
        file_path_obj = Path(file_path)
        if not file_path_obj.exists():
            raise FileNotFoundError(f"ãƒ•ã‚¡ã‚¤ãƒ«ãŒè¦‹ã¤ã‹ã‚Šã¾ã›ã‚“: {file_path}")
        
        file_size_mb = file_path_obj.stat().st_size / (1024 * 1024)
        if file_size_mb > self.max_file_size_mb:
            raise VideoFileTooLargeError(
                f"ãƒ•ã‚¡ã‚¤ãƒ«ã‚µã‚¤ã‚º({file_size_mb:.1f}MB)ãŒåˆ¶é™({self.max_file_size_mb}MB)ã‚’è¶…ãˆã¦ã„ã¾ã™ã€‚"
                "ãƒ•ã‚¡ã‚¤ãƒ«ã‚’å°ã•ãåˆ†å‰²ã™ã‚‹ã‹ã€è¨­å®šã®'max_file_size_mb'ã‚’å¢—ã‚„ã—ã¦ãã ã•ã„ã€‚"
            )

    def upload_file(self, file_path: str, mime_type: Optional[str] = None) -> Any:
        """ãƒ•ã‚¡ã‚¤ãƒ«ã‚’Gemini APIã«ã‚¢ãƒƒãƒ—ãƒ­ãƒ¼ãƒ‰
        
        Args:
            file_path (str): ã‚¢ãƒƒãƒ—ãƒ­ãƒ¼ãƒ‰ã™ã‚‹ãƒ•ã‚¡ã‚¤ãƒ«ã®ãƒ‘ã‚¹
            mime_type (str, optional): ãƒ•ã‚¡ã‚¤ãƒ«ã®MIMEã‚¿ã‚¤ãƒ— (éæ¨å¥¨ã€æ–°APIã§ã¯è‡ªå‹•æ¤œå‡º)
            
        Returns:
            Any: ã‚¢ãƒƒãƒ—ãƒ­ãƒ¼ãƒ‰ã•ã‚ŒãŸãƒ•ã‚¡ã‚¤ãƒ«ã‚ªãƒ–ã‚¸ã‚§ã‚¯ãƒˆ
            
        Raises:
            GeminiAPIError: ã‚¢ãƒƒãƒ—ãƒ­ãƒ¼ãƒ‰ã«å¤±æ•—ã—ãŸå ´åˆ
        """
        try:
            # ãƒ•ã‚¡ã‚¤ãƒ«ã‚µã‚¤ã‚ºã®ãƒã‚§ãƒƒã‚¯
            self._check_file_size(file_path)
            
            # ãƒ•ã‚¡ã‚¤ãƒ«ã‚’ã‚¢ãƒƒãƒ—ãƒ­ãƒ¼ãƒ‰
            logger.info(f"Uploading file: {file_path}")
            uploaded_file = self.client.files.upload(file=file_path)
            logger.info(f"File uploaded successfully: {uploaded_file.uri}")
            
            # ãƒ•ã‚¡ã‚¤ãƒ«å‡¦ç†ã®å®Œäº†ã‚’å¾…æ©Ÿï¼ˆACTIVEçŠ¶æ…‹ã«ãªã‚‹ã¾ã§ï¼‰
            if not self.wait_for_processing(uploaded_file):
                raise GeminiAPIError("ãƒ•ã‚¡ã‚¤ãƒ«ã®å‡¦ç†ãŒå®Œäº†ã—ã¾ã›ã‚“ã§ã—ãŸ")
            
            return uploaded_file
        except VideoFileTooLargeError:
            raise
        except Exception as e:
            error_msg = f"ãƒ•ã‚¡ã‚¤ãƒ«ã®ã‚¢ãƒƒãƒ—ãƒ­ãƒ¼ãƒ‰ã«å¤±æ•—ã—ã¾ã—ãŸ: {str(e)}"
            logger.error(error_msg)
            raise GeminiAPIError(error_msg)

    def wait_for_processing(self, file) -> bool:
        """ãƒ•ã‚¡ã‚¤ãƒ«ã®å‡¦ç†å®Œäº†ã‚’å¾…æ©Ÿ"""
        # ç”»åƒãƒ•ã‚¡ã‚¤ãƒ«ã®å ´åˆã¯å¾…æ©Ÿæ™‚é–“ã‚’çŸ­ç¸®
        max_retries = 10  # 30å›ã‹ã‚‰10å›ã«çŸ­ç¸®
        retry_delay = 2   # 5ç§’ã‹ã‚‰2ç§’ã«çŸ­ç¸®
        
        for attempt in range(max_retries):
            try:
                # ãƒ•ã‚¡ã‚¤ãƒ«ã®çŠ¶æ…‹ã‚’å–å¾—
                file_status = self.client.files.get(name=file.name)
                state_value = file_status.state
                
                # çŠ¶æ…‹ã‚’è©³ç´°ã«ãƒ­ã‚°å‡ºåŠ›
                logger.debug(f"File processing attempt {attempt + 1}/{max_retries}: {state_value} (type: {type(state_value)})")
                
                # æ§˜ã€…ãªå½¢å¼ã§ã®çŠ¶æ…‹ç¢ºèª
                state_str = str(state_value).upper()
                if "ACTIVE" in state_str:
                    logger.info(f"File processing completed: {state_value}")
                    return True
                    
                # å¤±æ•—çŠ¶æ…‹ã‚‚ãƒã‚§ãƒƒã‚¯
                if "FAILED" in state_str or "ERROR" in state_str:
                    logger.error(f"File processing failed with state: {state_value}")
                    return False
                
                # å‡¦ç†ä¸­çŠ¶æ…‹ã®ãƒ­ã‚°
                if "PROCESSING" in state_str or "PENDING" in state_str:
                    logger.debug(f"File still processing: {state_value}")
                    
                time.sleep(retry_delay)
                
            except Exception as e:
                logger.warning(f"Failed to get file status (attempt {attempt + 1}): {e}")
                if attempt == max_retries - 1:
                    logger.error(f"Failed to get file status after {max_retries} attempts")
                    # æœ€å¾Œã®è©¦è¡Œã§ã¯å‡¦ç†ã‚’ç¶šè¡Œã™ã‚‹ï¼ˆç”»åƒãŒã‚¢ãƒƒãƒ—ãƒ­ãƒ¼ãƒ‰æ¸ˆã¿ãªã‚‰ä½¿ãˆã‚‹å¯èƒ½æ€§ï¼‰
                    logger.info("Attempting to proceed with uploaded file despite status check failure")
                    return True
                time.sleep(retry_delay)
        
        return False

    def transcribe(
        self,
        file_path: str,
        media_type: str = MediaType.AUDIO,
        stream: bool = False
    ) -> Union[str, Iterator[str]]:
        """éŸ³å£°/å‹•ç”»ã®æ›¸ãèµ·ã“ã—ã‚’è¡Œã†"""
        # ãƒ•ã‚¡ã‚¤ãƒ«ã‚¢ãƒƒãƒ—ãƒ­ãƒ¼ãƒ‰
        uploaded = self.upload_file(file_path)
        contents = []
        # ã‚¹ãƒˆãƒªãƒ¼ãƒŸãƒ³ã‚° or ãƒãƒ¼ãƒãƒ«
        if stream:
            return self._transcribe_stream(contents, self.generation_config)
        else:
            return self._transcribe_normal(contents, self.generation_config)

    def _transcribe_stream(self, contents: List, config: Dict) -> Iterator[str]:
        """ã‚¹ãƒˆãƒªãƒ¼ãƒŸãƒ³ã‚°æ›¸ãèµ·ã“ã— (æœªå®Ÿè£…)"""
        raise NotImplementedError("Streaming transcription is not implemented")

    def _transcribe_normal(self, contents: List, config: Dict) -> str:
        """ãƒãƒ¼ãƒãƒ«æ›¸ãèµ·ã“ã— (æœªå®Ÿè£…)"""
        raise NotImplementedError("Normal transcription is not implemented")

    def generate_title(self, transcription_text: str) -> str:
        """ã‚¿ã‚¤ãƒˆãƒ«ã‚’ç”Ÿæˆã™ã‚‹"""
        # æ–°ã—ã„APIã‚’ä½¿ç”¨ã—ã¦ã‚¿ã‚¤ãƒˆãƒ«ã‚’ç”Ÿæˆ
        try:
            response = self.client.models.generate_content(
                model=self.title_model,
                contents=transcription_text
            )
            text = response.text
            try:
                data = json.loads(text)
                return data.get("title", text)
            except json.JSONDecodeError:
                logger.warning("ã‚¿ã‚¤ãƒˆãƒ«ç”Ÿæˆãƒ¬ã‚¹ãƒãƒ³ã‚¹ã®JSONè§£æã«å¤±æ•—ã€å…ƒãƒ†ã‚­ã‚¹ãƒˆã‚’è¿”ã—ã¾ã™")
                return text
        except Exception as e:
            logger.error(f"ã‚¿ã‚¤ãƒˆãƒ«ç”Ÿæˆã‚¨ãƒ©ãƒ¼: {e}")
            return ""

    def summarize_minutes(self, text: str, system_prompt: str = None) -> str:
        """è­°äº‹éŒ²ã‚’è¦ç´„ã™ã‚‹"""
        # æ–°ã—ã„APIã‚’ä½¿ç”¨ã—ã¦è­°äº‹éŒ²è¦ç´„ã‚’ç”Ÿæˆ
        prompt_text = system_prompt or self.system_prompt
        try:
            response = self.client.models.generate_content(
                model=self.minutes_model,
                contents=prompt_text
            )
            return response.text
        except Exception as e:
            logger.error(f"è­°äº‹éŒ²è¦ç´„ã‚¨ãƒ©ãƒ¼: {e}")
            return ""

    async def analyze_image(self, file_path: str, prompt: str) -> str:
        """ç”»åƒã‚’è§£æã—ã¦ãƒ†ã‚­ã‚¹ãƒˆã‚’ç”Ÿæˆã™ã‚‹ï¼ˆéåŒæœŸç‰ˆï¼‰
        
        Args:
            file_path (str): è§£æã™ã‚‹ç”»åƒãƒ•ã‚¡ã‚¤ãƒ«ã®ãƒ‘ã‚¹
            prompt (str): è§£æã®æŒ‡ç¤ºãƒ—ãƒ­ãƒ³ãƒ—ãƒˆ
            
        Returns:
            str: è§£æçµæœã®ãƒ†ã‚­ã‚¹ãƒˆ
            
        Raises:
            GeminiAPIError: è§£æã«å¤±æ•—ã—ãŸå ´åˆ
        """
        try:
            logger.info(f"ğŸ¯ [éåŒæœŸ] Starting image analysis: {os.path.basename(file_path)}")
            logger.debug(f"ğŸ”§ [éåŒæœŸ] Image analysis prompt length: {len(prompt)} characters")
            start_time = time.time()
            
            # ãƒ•ã‚¡ã‚¤ãƒ«ã‚µã‚¤ã‚ºã®ãƒã‚§ãƒƒã‚¯
            logger.debug(f"ğŸ“ [éåŒæœŸ] Checking file size for: {file_path}")
            await asyncio.to_thread(self._check_file_size, file_path)
            logger.debug(f"âœ… [éåŒæœŸ] File size check completed")
            
            # ç”»åƒãƒ•ã‚¡ã‚¤ãƒ«ã‚’ã‚¢ãƒƒãƒ—ãƒ­ãƒ¼ãƒ‰
            logger.info(f"â¬†ï¸ [éåŒæœŸ] Uploading image for analysis: {file_path}")
            uploaded_file = await asyncio.to_thread(self.client.files.upload, file=file_path)
            logger.info(f"âœ… [éåŒæœŸ] Image uploaded successfully: {uploaded_file.uri}")
            upload_time = time.time() - start_time
            logger.debug(f"â±ï¸ [éåŒæœŸ] Upload completed in {upload_time:.2f} seconds")
            
            # ãƒ•ã‚¡ã‚¤ãƒ«å‡¦ç†ã®å®Œäº†ã‚’å¾…æ©Ÿ
            logger.debug(f"â³ [éåŒæœŸ] Waiting for image processing completion...")
            if not await asyncio.to_thread(self.wait_for_processing, uploaded_file):
                raise GeminiAPIError("ç”»åƒãƒ•ã‚¡ã‚¤ãƒ«ã®å‡¦ç†ãŒå®Œäº†ã—ã¾ã›ã‚“ã§ã—ãŸ")
            logger.debug(f"âœ… [éåŒæœŸ] Image processing completed")
            
            # ç”»åƒè§£æã®å®Ÿè¡Œ (æœ€æ–°APIã§ã¯ uploaded_file ã‚’ç›´æ¥ contents ã«æ¸¡ã™)
            analysis_start = time.time()
            logger.info(f"ğŸ¤– [éåŒæœŸ] Starting AI image analysis...")
            response = await asyncio.to_thread(
                self.client.models.generate_content,
                model=self.transcription_model,
                contents=[prompt, uploaded_file],
                config=types.GenerateContentConfig(
                    temperature=self.image_analysis_config["temperature"],
                    top_p=self.image_analysis_config["top_p"],
                    top_k=self.image_analysis_config["top_k"],
                    max_output_tokens=self.image_analysis_config["max_output_tokens"],
                )
            )
            analysis_time = time.time() - analysis_start
            logger.debug(f"ğŸ¯ [éåŒæœŸ] Image AI analysis completed in {analysis_time:.2f} seconds")
            
            # ãƒ•ã‚¡ã‚¤ãƒ«ã‚’å‰Šé™¤ï¼ˆã‚ªãƒ—ã‚·ãƒ§ãƒ³ï¼šãƒªã‚½ãƒ¼ã‚¹ç¯€ç´„ã®ãŸã‚ï¼‰
            try:
                logger.debug(f"ğŸ—‘ï¸ [éåŒæœŸ] Deleting temporary image file...")
                await asyncio.to_thread(self.client.files.delete, name=uploaded_file.name)
                logger.info(f"âœ… [éåŒæœŸ] Temporary image file deleted: {uploaded_file.name}")
            except Exception as e:
                logger.warning(f"âš ï¸ [éåŒæœŸ] Failed to delete temporary file: {e}")
            
            result = response.text
            total_time = time.time() - start_time
            logger.info(f"ğŸ‰ [éåŒæœŸ] Image analysis completed successfully in {total_time:.2f} seconds, response length: {len(result)} characters")
            return result
            
        except FileNotFoundError as e:
            error_msg = f"ç”»åƒãƒ•ã‚¡ã‚¤ãƒ«ãŒè¦‹ã¤ã‹ã‚Šã¾ã›ã‚“: {str(e)}"
            logger.error(f"âŒ [éåŒæœŸ] {error_msg}")
            raise GeminiAPIError(error_msg)
        except VideoFileTooLargeError as e:
            error_msg = f"ç”»åƒãƒ•ã‚¡ã‚¤ãƒ«ã‚µã‚¤ã‚ºã‚¨ãƒ©ãƒ¼: {str(e)}"
            logger.error(f"âŒ [éåŒæœŸ] {error_msg}")
            raise GeminiAPIError(error_msg)
        except Exception as e:
            error_msg = f"ç”»åƒè§£æã«å¤±æ•—ã—ã¾ã—ãŸ: {str(e)}"
            logger.error(f"âŒ [éåŒæœŸ] {error_msg}")
            logger.debug(f"ğŸ” [éåŒæœŸ] Image analysis error details: {type(e).__name__}: {e}")
            raise GeminiAPIError(error_msg)

    async def analyze_video(self, file_path: str, prompt: str) -> str:
        """å‹•ç”»ã‚’è§£æã—ã¦ãƒ†ã‚­ã‚¹ãƒˆã‚’ç”Ÿæˆã™ã‚‹ï¼ˆéåŒæœŸç‰ˆï¼‰
        
        Args:
            file_path (str): è§£æã™ã‚‹å‹•ç”»ãƒ•ã‚¡ã‚¤ãƒ«ã®ãƒ‘ã‚¹
            prompt (str): è§£æã®æŒ‡ç¤ºãƒ—ãƒ­ãƒ³ãƒ—ãƒˆ
            
        Returns:
            str: è§£æçµæœã®ãƒ†ã‚­ã‚¹ãƒˆ
            
        Raises:
            GeminiAPIError: è§£æã«å¤±æ•—ã—ãŸå ´åˆ
        """
        try:
            logger.info(f"ğŸ¬ [éåŒæœŸ] Starting video analysis: {os.path.basename(file_path)}")
            logger.debug(f"ğŸ”§ [éåŒæœŸ] Video analysis prompt length: {len(prompt)} characters")
            start_time = time.time()
            
            # ãƒ•ã‚¡ã‚¤ãƒ«ã‚µã‚¤ã‚ºã®ãƒã‚§ãƒƒã‚¯
            logger.debug(f"ğŸ“ [éåŒæœŸ] Checking file size for: {file_path}")
            await asyncio.to_thread(self._check_file_size, file_path)
            logger.debug(f"âœ… [éåŒæœŸ] File size check completed")
            
            # å‹•ç”»ãƒ•ã‚¡ã‚¤ãƒ«ã‚’ã‚¢ãƒƒãƒ—ãƒ­ãƒ¼ãƒ‰
            logger.info(f"â¬†ï¸ [éåŒæœŸ] Uploading video for analysis: {file_path}")
            uploaded_file = await asyncio.to_thread(self.client.files.upload, file=file_path)
            logger.info(f"âœ… [éåŒæœŸ] Video uploaded successfully: {uploaded_file.uri}")
            upload_time = time.time() - start_time
            logger.debug(f"â±ï¸ [éåŒæœŸ] Upload completed in {upload_time:.2f} seconds")
            
            # ãƒ•ã‚¡ã‚¤ãƒ«å‡¦ç†ã®å®Œäº†ã‚’å¾…æ©Ÿï¼ˆå‹•ç”»ã¯æ™‚é–“ãŒã‹ã‹ã‚‹å ´åˆãŒã‚ã‚Šã¾ã™ï¼‰
            logger.info(f"â³ [éåŒæœŸ] Waiting for video processing to complete...")
            if not await asyncio.to_thread(self.wait_for_processing, uploaded_file):
                raise GeminiAPIError("å‹•ç”»ãƒ•ã‚¡ã‚¤ãƒ«ã®å‡¦ç†ãŒå®Œäº†ã—ã¾ã›ã‚“ã§ã—ãŸ")
            
            processing_time = time.time() - start_time
            logger.debug(f"âœ… [éåŒæœŸ] Video processing completed in {processing_time:.2f} seconds")
            
            # å‹•ç”»è§£æã®å®Ÿè¡Œ (æœ€æ–°APIã§ã¯ uploaded_file ã‚’ç›´æ¥ contents ã«æ¸¡ã™)
            analysis_start = time.time()
            logger.info(f"ğŸ¤– [éåŒæœŸ] Starting AI video analysis...")
            response = await asyncio.to_thread(
                self.client.models.generate_content,
                model=self.transcription_model,
                contents=[prompt, uploaded_file],
                config=types.GenerateContentConfig(
                    temperature=self.video_analysis_config["temperature"],
                    top_p=self.video_analysis_config["top_p"],
                    top_k=self.video_analysis_config["top_k"],
                    max_output_tokens=self.video_analysis_config["max_output_tokens"],
                )
            )
            analysis_time = time.time() - analysis_start
            logger.debug(f"ğŸ¬ [éåŒæœŸ] Video AI analysis completed in {analysis_time:.2f} seconds")
            
            # ãƒ•ã‚¡ã‚¤ãƒ«ã‚’å‰Šé™¤ï¼ˆã‚ªãƒ—ã‚·ãƒ§ãƒ³ï¼šãƒªã‚½ãƒ¼ã‚¹ç¯€ç´„ã®ãŸã‚ï¼‰
            try:
                logger.debug(f"ğŸ—‘ï¸ [éåŒæœŸ] Deleting temporary video file...")
                await asyncio.to_thread(self.client.files.delete, name=uploaded_file.name)
                logger.info(f"âœ… [éåŒæœŸ] Temporary video file deleted: {uploaded_file.name}")
            except Exception as e:
                logger.warning(f"âš ï¸ [éåŒæœŸ] Failed to delete temporary file: {e}")
            
            result = response.text
            total_time = time.time() - start_time
            logger.info(f"ğŸ‰ [éåŒæœŸ] Video analysis completed successfully in {total_time:.2f} seconds, response length: {len(result)} characters")
            return result
            
        except FileNotFoundError as e:
            error_msg = f"å‹•ç”»ãƒ•ã‚¡ã‚¤ãƒ«ãŒè¦‹ã¤ã‹ã‚Šã¾ã›ã‚“: {str(e)}"
            logger.error(f"âŒ [éåŒæœŸ] {error_msg}")
            raise GeminiAPIError(error_msg)
        except VideoFileTooLargeError as e:
            error_msg = f"å‹•ç”»ãƒ•ã‚¡ã‚¤ãƒ«ã‚µã‚¤ã‚ºã‚¨ãƒ©ãƒ¼: {str(e)}"
            logger.error(f"âŒ [éåŒæœŸ] {error_msg}")
            raise GeminiAPIError(error_msg)
        except Exception as e:
            error_msg = f"å‹•ç”»è§£æã«å¤±æ•—ã—ã¾ã—ãŸ: {str(e)}"
            logger.error(f"âŒ [éåŒæœŸ] {error_msg}")
            logger.debug(f"ğŸ” [éåŒæœŸ] Video analysis error details: {type(e).__name__}: {e}")
            raise GeminiAPIError(error_msg)

    async def analyze_media(self, file_path: str, prompt: str, media_type: str = None) -> str:
        """ãƒ¡ãƒ‡ã‚£ã‚¢ãƒ•ã‚¡ã‚¤ãƒ«ï¼ˆç”»åƒãƒ»å‹•ç”»ï¼‰ã‚’è§£æã—ã¦ãƒ†ã‚­ã‚¹ãƒˆã‚’ç”Ÿæˆã™ã‚‹æ±ç”¨ãƒ¡ã‚½ãƒƒãƒ‰ï¼ˆéåŒæœŸç‰ˆï¼‰
        
        Args:
            file_path (str): è§£æã™ã‚‹ãƒ¡ãƒ‡ã‚£ã‚¢ãƒ•ã‚¡ã‚¤ãƒ«ã®ãƒ‘ã‚¹
            prompt (str): è§£æã®æŒ‡ç¤ºãƒ—ãƒ­ãƒ³ãƒ—ãƒˆ
            media_type (str, optional): ãƒ¡ãƒ‡ã‚£ã‚¢ã‚¿ã‚¤ãƒ— ("image" or "video")
                                       Noneã®å ´åˆã¯æ‹¡å¼µå­ã‹ã‚‰è‡ªå‹•åˆ¤å®š
            
        Returns:
            str: è§£æçµæœã®ãƒ†ã‚­ã‚¹ãƒˆ
            
        Raises:
            GeminiAPIError: è§£æã«å¤±æ•—ã—ãŸå ´åˆ
            ValueError: ã‚µãƒãƒ¼ãƒˆã•ã‚Œã¦ã„ãªã„ãƒ•ã‚¡ã‚¤ãƒ«å½¢å¼ã®å ´åˆ
        """
        # ãƒ¡ãƒ‡ã‚£ã‚¢ã‚¿ã‚¤ãƒ—ã®è‡ªå‹•åˆ¤å®š
        if media_type is None:
            file_ext = Path(file_path).suffix.lower()
            if file_ext in ['.jpg', '.jpeg', '.png']:
                media_type = MediaType.IMAGE
            elif file_ext in ['.mp4']:
                media_type = MediaType.VIDEO
            else:
                raise ValueError(f"ã‚µãƒãƒ¼ãƒˆã•ã‚Œã¦ã„ãªã„ãƒ•ã‚¡ã‚¤ãƒ«å½¢å¼ã§ã™: {file_ext}")
        
        # ãƒ¡ãƒ‡ã‚£ã‚¢ã‚¿ã‚¤ãƒ—ã«å¿œã˜ã¦é©åˆ‡ãªãƒ¡ã‚½ãƒƒãƒ‰ã‚’å‘¼ã³å‡ºã—
        if media_type == MediaType.IMAGE:
            return await self.analyze_image(file_path, prompt)
        elif media_type == MediaType.VIDEO:
            return await self.analyze_video(file_path, prompt)
        else:
            raise ValueError(f"ã‚µãƒãƒ¼ãƒˆã•ã‚Œã¦ã„ãªã„ãƒ¡ãƒ‡ã‚£ã‚¢ã‚¿ã‚¤ãƒ—ã§ã™: {media_type}") 