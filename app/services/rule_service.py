import os
import json
import logging
import re
from typing import Any, Dict, List, Optional
from datetime import datetime
import sys
import shutil
from pathlib import Path
import time
import asyncio

from utils.config import config_manager
from .gemini_api import GeminiAPI, GeminiAPIError

logger = logging.getLogger(__name__)

class ProcessMode:
    """å‡¦ç†ãƒ¢ãƒ¼ãƒ‰å®šç¾©"""
    NORMAL = "normal"      # ãƒ†ã‚­ã‚¹ãƒˆå‡¦ç†
    IMAGE = "image"        # ç”»åƒå‡¦ç†  
    VIDEO = "video"        # å‹•ç”»å‡¦ç†
    AUDIO = "audio"        # éŸ³å£°å‡¦ç†

class RuleService:
    """
    ãƒ«ãƒ¼ãƒ«ç®¡ç†APIã‚¯ãƒ©ã‚¤ã‚¢ãƒ³ãƒˆã®ã‚¹ã‚±ãƒ«ãƒˆãƒ³
    create_rule / regenerate_rule / get_rules / delete_rule / apply_rule ã‚’æä¾›ã™ã‚‹
    """
    def __init__(self, rules_path: Optional[str] = None):
        # å±¥æ­´ä¿å­˜å…ˆãƒ•ã‚¡ã‚¤ãƒ«ãƒ‘ã‚¹ã®è¨­å®š
        if getattr(sys, 'frozen', False):
            # PyInstaller onefileå®Ÿè¡Œç’°å¢ƒæ™‚: exeã¨åŒã˜ãƒ•ã‚©ãƒ«ãƒ€ã«persistentã«é…ç½®
            exec_dir = os.path.dirname(sys.executable)
            # ãƒ‘ãƒƒã‚±ãƒ¼ã‚¸å†…ã®ãƒ‡ãƒ•ã‚©ãƒ«ãƒˆãƒ•ã‚¡ã‚¤ãƒ«ãƒ‘ã‚¹
            packaged_rules = os.path.join(sys._MEIPASS, 'history_rules.json')
            # æ°¸ç¶šåŒ–ç”¨ãƒ‘ã‚¹
            persistent_rules = os.path.join(exec_dir, 'history_rules.json')
            # åˆå›èµ·å‹•æ™‚ã«ã‚³ãƒ”ãƒ¼
            if not os.path.exists(persistent_rules):
                try:
                    shutil.copy(packaged_rules, persistent_rules)
                    logger.info(f"Copied default history to {persistent_rules}")
                except Exception as e:
                    logger.error(f"Failed to copy default history_rules.json: {e}")
            self.rules_path = persistent_rules
        else:
            # é€šå¸¸å®Ÿè¡Œæ™‚ã¯UIãƒ•ã‚©ãƒ«ãƒ€å†…ã®history_rules.jsonã‚’åˆ©ç”¨
            base_dir = os.path.abspath(os.path.join(os.path.dirname(__file__), '..', '..'))
            default_path = os.path.join(base_dir, 'app', 'ui', 'history_rules.json')
            self.rules_path = rules_path or default_path
        self._load_rules()
        self.gemini = GeminiAPI()

    def _load_rules(self) -> None:
        """ãƒ­ãƒ¼ã‚«ãƒ«ã‚¹ãƒˆãƒ¬ãƒ¼ã‚¸ã‹ã‚‰ãƒ«ãƒ¼ãƒ«ä¸€è¦§ã‚’èª­ã¿è¾¼ã‚€"""
        if os.path.exists(self.rules_path):
            try:
                with open(self.rules_path, 'r', encoding='utf-8') as f:
                    data = json.load(f)
                # JSON ãŒ 'rules' ã‚­ãƒ¼ã‚’æŒã¤å ´åˆã¯ãã®é…åˆ—ã‚’åˆ©ç”¨ã€ãƒªã‚¹ãƒˆã®å ´åˆã¯ãã®ã¾ã¾
                if isinstance(data, dict) and 'rules' in data:
                    self._rules = data['rules']
                elif isinstance(data, list):
                    self._rules = data
                else:
                    logger.warning(f"Unexpected rules format in {self.rules_path}")
                    self._rules = []
                logger.debug(f"Loaded rules from {self.rules_path}")
                
                # IDãƒã‚¤ã‚°ãƒ¬ãƒ¼ã‚·ãƒ§ãƒ³: idãƒ•ã‚£ãƒ¼ãƒ«ãƒ‰ãŒãªã„ãƒ«ãƒ¼ãƒ«ã«é€£ç•ªIDã‚’ä»˜ä¸
                needs_save = False
                for idx, rule in enumerate(self._rules):
                    if "id" not in rule:
                        rule["id"] = idx
                        logger.info(f"Assigned new id={idx} to rule title={rule.get('title')}")
                        needs_save = True
                    # ãƒ¢ãƒ¼ãƒ‰ãƒã‚¤ã‚°ãƒ¬ãƒ¼ã‚·ãƒ§ãƒ³: modeãƒ•ã‚£ãƒ¼ãƒ«ãƒ‰ãŒãªã„ãƒ«ãƒ¼ãƒ«ã«normalãƒ¢ãƒ¼ãƒ‰ã‚’ä»˜ä¸
                    if "mode" not in rule:
                        rule["mode"] = ProcessMode.NORMAL
                        logger.info(f"Assigned normal mode to rule id={rule.get('id')}")
                        needs_save = True
                
                if needs_save:
                    logger.info("Migrated rules, saving updated rules with IDs and modes.")
                    self._save_rules()

                # --- è¿½åŠ : stray 'rule_name' ã‚­ãƒ¼ã®å‰Šé™¤ã¨é‡è¤‡IDã®ã‚¯ãƒªãƒ¼ãƒ³ã‚¢ãƒƒãƒ— ---
                cleanup_save = False
                # 'rule_name' ãƒ•ã‚£ãƒ¼ãƒ«ãƒ‰ãŒã‚ã‚Œã°å‰Šé™¤
                for rule in self._rules:
                    if 'rule_name' in rule:
                        del rule['rule_name']
                        logger.info(f"Removed stray 'rule_name' from rule id={rule.get('id')}")
                        cleanup_save = True
                # é‡è¤‡IDã®ãƒ«ãƒ¼ãƒ«ã‚’é™¤å¤–
                seen_ids = set()
                unique_rules = []
                for rule in self._rules:
                    rid = rule.get('id')
                    if rid in seen_ids:
                        logger.warning(f"Duplicate rule id={rid} detected and removed")
                        cleanup_save = True
                        continue
                    seen_ids.add(rid)
                    unique_rules.append(rule)
                self._rules = unique_rules
                if cleanup_save:
                    logger.info("Cleaned up stray fields and duplicates, saving rules.")
                    self._save_rules()
            except Exception as e:
                logger.error(f"Failed to load rules: {e}")
                self._rules = []
        else:
            self._rules = []

    def _save_rules(self) -> None:
        """ç¾åœ¨ã®ãƒ«ãƒ¼ãƒ«ä¸€è¦§ã‚’ãƒ­ãƒ¼ã‚«ãƒ«ã‚¹ãƒˆãƒ¬ãƒ¼ã‚¸ã«ä¿å­˜ã™ã‚‹"""
        try:
            with open(self.rules_path, 'w', encoding='utf-8') as f:
                json.dump(self._rules, f, ensure_ascii=False, indent=2)
            logger.debug(f"Saved rules to {self.rules_path}")
        except Exception as e:
            logger.error(f"Failed to save rules: {e}")

    def _generate_json_example(self, sample_data: Dict[str, Any]) -> Dict[str, str]:
        """ã‚µãƒ³ãƒ—ãƒ«ãƒ‡ãƒ¼ã‚¿ã‹ã‚‰å‡ºåŠ›ç”¨JSONãƒ•ã‚©ãƒ¼ãƒãƒƒãƒˆä¾‹ã‚’ç”Ÿæˆ"""
        headers = sample_data.get('headers', [])
        # "AIã®é€²æ—"ã¨"å…ƒã®å€¤"ã‚’é™¤ãå…¨ã¦ã®ãƒ˜ãƒƒãƒ€ãƒ¼ã‚’å¯¾è±¡ã¨ã™ã‚‹
        output_headers = [h for idx, h in enumerate(headers) if idx >= 2 and h.strip()]
        # å„é …ç›®ã«ç©ºæ–‡å­—ã‚’è¨­å®šã—ãŸJSONãƒ†ãƒ³ãƒ—ãƒ¬ãƒ¼ãƒˆã‚’ç”Ÿæˆ
        example_map = {header: "" for header in output_headers}
        return example_map

    def _generate_text_rule_prompt(self, samples: List[Dict[str, Any]], fields: List[str]) -> str:
        """ãƒ†ã‚­ã‚¹ãƒˆãƒ¢ãƒ¼ãƒ‰ç”¨ã®ãƒ«ãƒ¼ãƒ«ãƒ—ãƒ­ãƒ³ãƒ—ãƒˆç”Ÿæˆ"""
        prompt_instructions = []
        # ãƒ˜ãƒƒãƒ€ãƒ¼èª¬æ˜
        field_list = "ã€".join(fields)
        prompt_instructions.append(
            f"ä»¥ä¸‹ã«ç¤ºã™ã®ã¯ã€ã‚ã‚‹å…¥åŠ›ãƒ‡ãƒ¼ã‚¿ï¼ˆã€Œå…ƒã®å€¤ã€ï¼‰ã¨ã€ãã‚Œã«å¯¾ã—ã¦ç‰¹å®šã®å‡¦ç†ã‚’è¡Œã£ãŸçµæœå¾—ã‚‰ã‚ŒãŸè¤‡æ•°ã®å‡ºåŠ›é …ç›®ï¼ˆ{field_list}ï¼‰ã®å…·ä½“ä¾‹ã§ã™ã€‚\n"
        )
        prompt_instructions.append("**ãƒ‡ãƒ¼ã‚¿ä¾‹:**")
        # ã‚µãƒ³ãƒ—ãƒ«ã”ã¨ã®ä¾‹ã‚’å‹•çš„ã«ç”Ÿæˆ
        for idx, s in enumerate(samples):
            prompt_instructions.append(f"ä¾‹{idx+1}")
            prompt_instructions.append(f"å…ƒã®å€¤: {s.get('input', '')}")
            for f in fields:
                prompt_instructions.append(f"é …ç›®å={f}: {s.get('output', {}).get(f, '')}")
        # ä¾é ¼éƒ¨åˆ†
        prompt_instructions.append("\n**ä¾é ¼:**")
        prompt_instructions.append(
            f"ã“ã‚Œã‚‰ã®å…¥åŠ›ï¼ˆå…ƒã®å€¤ï¼‰ã¨å‡ºåŠ›ï¼ˆå„é …ç›®ï¼‰ã®é–¢ä¿‚æ€§ã‚’åˆ†æã—ã€ã€Œå…ƒã®å€¤ã€ã®ã‚ˆã†ãªãƒ‡ãƒ¼ã‚¿ã‚’å…¥åŠ›ã¨ã—ã¦ä¸ãˆãŸéš›ã«ã€ã“ã‚Œã‚‰ã®å‡ºåŠ›é …ç›®ï¼ˆ{field_list}ï¼‰ã‚’ç”Ÿæˆã•ã›ã‚‹ãŸã‚ã«AIã«ä¸ãˆã‚‹ã¹ãæŒ‡ç¤ºï¼ˆãƒ—ãƒ­ãƒ³ãƒ—ãƒˆï¼‰ã‚’æ¨æ¸¬ã—ã€ä½œæˆã—ã¦ãã ã•ã„ã€‚"
        )
        prompt_instructions.append("\nç”Ÿæˆã™ã‚‹ãƒ—ãƒ­ãƒ³ãƒ—ãƒˆã®è¦ä»¶:")
        prompt_instructions.append("* æç¤ºã•ã‚ŒãŸä¾‹ã ã‘ã§ãªãã€ä»–ã®åŒæ§˜ã®å…¥åŠ›ã«å¯¾ã—ã¦ã‚‚é©ç”¨ã§ãã‚‹ã‚ˆã†ãªã€æ±ç”¨çš„ãªæŒ‡ç¤ºã«ã—ã¦ãã ã•ã„ã€‚")
        prompt_instructions.append("* ãƒ—ãƒ­ãƒ³ãƒ—ãƒˆã¯ã€AIã«å¯¾ã™ã‚‹æŒ‡ç¤ºã¨ã—ã¦æ©Ÿèƒ½ã™ã‚‹ã€ç«¯çš„ã§çŸ­ã„æ–‡ç« ã«ã¾ã¨ã‚ã‚‹ã“ã¨ã€‚è¿”ç­”ä¾‹ã¯åˆ¥é€”æ·»ä»˜ã™ã‚‹ãŸã‚ã“ã“ã§ã¯ç«¯çš„ãªè¡¨ç¾ã‚’å¿ƒãŒã‘ã‚‹ã“ã¨")
        # JSONå½¢å¼ã§å‡ºåŠ›ã•ã›ã€promptã‚­ãƒ¼ã®å€¤ã‚’å–å¾—ã™ã‚‹æŒ‡ç¤ºã‚’è¿½åŠ 
        prompt_instructions.append("è¿”ç­”ã¯JSONå½¢å¼ã§ {\"prompt\": \"<ãƒ—ãƒ­ãƒ³ãƒ—ãƒˆ>\"} ã®ã¿ã‚’è¿”ã—ã€ä»–ã®æ–‡è¨€ã‚’å«ã‚ãªã„ã§ãã ã•ã„ã€‚")
        # AIã«é€ä¿¡ã™ã‚‹ãƒ—ãƒ­ãƒ³ãƒ—ãƒˆå…¨æ–‡ã‚’ãƒ­ã‚°å‡ºåŠ›ã™ã‚‹
        prompt_content = "\n".join(prompt_instructions)
        logger.info(f"â˜…aiã«é€ã£ãŸå…¨æ–‡ã ã‚ˆâ˜…\n{prompt_content}")
        
        try:
            logger.info("Generating rule prompt via Gemini API (JSON format)...")
            resp1 = self.gemini.client.models.generate_content(
                model=self.gemini.transcription_model,
                contents=prompt_content
            )
            text = resp1.text.strip()
            # ã‚³ãƒ¼ãƒ‰ãƒ–ãƒ­ãƒƒã‚¯ã‚„ä½™åˆ†ãªè¨˜å·ã‚’é™¤å»
            if text.startswith("```"):
                text = re.sub(r"```(?:json)?\\n?", "", text)
                text = text.rstrip("`\\n ")
            # JSONéƒ¨åˆ†ã‚’æŠ½å‡ºã—ã¦ãƒ‘ãƒ¼ã‚¹
            start = text.find("{")
            end = text.rfind("}")
            json_str = text[start:end+1] if start != -1 and end != -1 else text
            try:
                data = json.loads(json_str)
                rule_prompt = data.get("prompt", "").strip()
                logger.info(f"Parsed rule prompt from JSON: {rule_prompt}")
                return rule_prompt
            except Exception as e:
                logger.error(f"ãƒ—ãƒ­ãƒ³ãƒ—ãƒˆJSONãƒ‘ãƒ¼ã‚¹ã‚¨ãƒ©ãƒ¼: {e}, raw text: '{text}'")
                return ""
        except Exception as e:
            logger.error(f"ãƒ—ãƒ­ãƒ³ãƒ—ãƒˆç”Ÿæˆã‚¨ãƒ©ãƒ¼: {e}")
            return ""

    async def _generate_media_rule_prompt(self, samples: List[Dict[str, Any]], fields: List[str], mode: str) -> str:
        """ç”»åƒãƒ»å‹•ç”»ãƒ¢ãƒ¼ãƒ‰ç”¨ã®ãƒ«ãƒ¼ãƒ«ãƒ—ãƒ­ãƒ³ãƒ—ãƒˆç”Ÿæˆï¼ˆéåŒæœŸç‰ˆï¼‰"""
        logger.info(f"ğŸ¬ Starting media rule prompt generation for mode: {mode}")
        logger.info(f"ğŸ“Š Input samples count: {len(samples)}, Fields: {fields}")
        
        # ãƒ•ã‚£ãƒ¼ãƒ«ãƒ‰ãƒªã‚¹ãƒˆã‚’ä½œæˆ
        field_list = "ã€".join(fields)
        
        # å®Ÿéš›ã®ãƒ¡ãƒ‡ã‚£ã‚¢ãƒ•ã‚¡ã‚¤ãƒ«è§£æçµæœã‚’å«ã‚€ä¾‹ã‚’ç”Ÿæˆ
        analyzed_examples = []
        
        for idx, sample in enumerate(samples):
            file_path = sample.get('input', '')
            expected_outputs = sample.get('output', {})
            
            logger.info(f"ğŸ” Analyzing sample {idx+1}/{len(samples)}: {file_path}")
            
            try:
                # ãƒ•ã‚¡ã‚¤ãƒ«ãƒ‘ã‚¹ã®æ¤œè¨¼
                file_path_obj = Path(file_path)
                if not file_path_obj.exists():
                    logger.warning(f"âš ï¸ Sample file not found: {file_path}, using filename only")
                    analyzed_examples.append({
                        'input_description': f"ãƒ•ã‚¡ã‚¤ãƒ«å: {file_path}",
                        'outputs': expected_outputs
                    })
                    continue
                
                # ãƒ•ã‚¡ã‚¤ãƒ«ã‚µã‚¤ã‚ºæƒ…å ±ã‚’ãƒ­ã‚°ã«å‡ºåŠ›
                file_size = file_path_obj.stat().st_size / (1024 * 1024)  # MB
                logger.info(f"ğŸ“ File size: {file_size:.2f} MB")
                
                # ãƒ¡ãƒ‡ã‚£ã‚¢ãƒ•ã‚¡ã‚¤ãƒ«ã‚’è§£æ
                analysis_prompt = f"ã“ã®ãƒ•ã‚¡ã‚¤ãƒ«ã®å†…å®¹ã‚’è©³ã—ãèª¬æ˜ã—ã¦ãã ã•ã„ã€‚ç‰¹ã«ä»¥ä¸‹ã®è¦³ç‚¹ã‹ã‚‰åˆ†æã—ã¦ãã ã•ã„ï¼š\n"
                for field in fields:
                    analysis_prompt += f"- {field}ã«é–¢é€£ã™ã‚‹è¦ç´ \n"
                
                logger.debug(f"ğŸ¤– Media analysis prompt: {analysis_prompt}")
                logger.info(f"ğŸš€ Starting {mode} analysis via Gemini API...")
                
                # ãƒ¢ãƒ¼ãƒ‰ã«å¿œã˜ã¦è§£æAPIã‚’å‘¼ã³å‡ºã—ï¼ˆéåŒæœŸï¼‰
                analysis_start_time = time.time()
                if mode == ProcessMode.IMAGE:
                    analysis_result = await self.gemini.analyze_image(file_path, analysis_prompt)
                elif mode == ProcessMode.VIDEO:
                    analysis_result = await self.gemini.analyze_video(file_path, analysis_prompt)
                else:  # AUDIO
                    analysis_result = await self.gemini.analyze_audio(file_path, analysis_prompt)
                
                analysis_time = time.time() - analysis_start_time
                logger.info(f"âœ… Analysis completed in {analysis_time:.2f} seconds")
                logger.debug(f"ğŸ“ Analysis result for {file_path}: {analysis_result[:100]}...")
                
                analyzed_examples.append({
                    'input_description': f"ãƒ•ã‚¡ã‚¤ãƒ«å†…å®¹: {analysis_result[:200]}..." if len(analysis_result) > 200 else f"ãƒ•ã‚¡ã‚¤ãƒ«å†…å®¹: {analysis_result}",
                    'outputs': expected_outputs
                })
                
            except Exception as e:
                logger.error(f"âŒ Failed to analyze media file {file_path}: {e}")
                # ã‚¨ãƒ©ãƒ¼ã®å ´åˆã¯ãƒ•ã‚¡ã‚¤ãƒ«åã®ã¿ã‚’ä½¿ç”¨
                analyzed_examples.append({
                    'input_description': f"ãƒ•ã‚¡ã‚¤ãƒ«å: {file_path} (è§£æã‚¨ãƒ©ãƒ¼: {e})",
                    'outputs': expected_outputs
                })
        
        logger.info(f"ğŸ“‹ Successfully analyzed {len([ex for ex in analyzed_examples if 'è§£æã‚¨ãƒ©ãƒ¼' not in ex['input_description']])}/{len(samples)} samples")
        
        # è§£æçµæœã‚’åŸºã«ãƒ—ãƒ­ãƒ³ãƒ—ãƒˆç”ŸæˆæŒ‡ç¤ºã‚’ä½œæˆ
        prompt_instructions = []
        
        # ãƒ˜ãƒƒãƒ€ãƒ¼èª¬æ˜ï¼ˆãƒ¡ãƒ‡ã‚£ã‚¢ãƒ•ã‚¡ã‚¤ãƒ«ç”¨ï¼‰
        if mode == ProcessMode.IMAGE:
            media_type_name = "ç”»åƒ"
        elif mode == ProcessMode.VIDEO:
            media_type_name = "å‹•ç”»"
        else:  # AUDIO
            media_type_name = "éŸ³å£°"
        prompt_instructions.append(
            f"ä»¥ä¸‹ã«ç¤ºã™ã®ã¯ã€{media_type_name}ãƒ•ã‚¡ã‚¤ãƒ«ã®è§£æå†…å®¹ï¼ˆã€Œå…ƒã®å€¤ã€ï¼‰ã¨ã€ãã‚Œã«å¯¾ã—ã¦ç‰¹å®šã®å‡¦ç†ã‚’è¡Œã£ãŸçµæœå¾—ã‚‰ã‚ŒãŸè¤‡æ•°ã®å‡ºåŠ›é …ç›®ï¼ˆ{field_list}ï¼‰ã®å…·ä½“ä¾‹ã§ã™ã€‚\n"
        )
        prompt_instructions.append("**ãƒ‡ãƒ¼ã‚¿ä¾‹:**")
        
        # è§£æçµæœã‚’å«ã‚€ä¾‹ã‚’è¿½åŠ 
        for idx, example in enumerate(analyzed_examples):
            prompt_instructions.append(f"ä¾‹{idx+1}")
            prompt_instructions.append(f"å…ƒã®å€¤: {example['input_description']}")
            for field in fields:
                output_value = example['outputs'].get(field, '')
                prompt_instructions.append(f"é …ç›®å={field}: {output_value}")
        
        # ä¾é ¼éƒ¨åˆ†ï¼ˆãƒ¡ãƒ‡ã‚£ã‚¢ãƒ•ã‚¡ã‚¤ãƒ«ç”¨ï¼‰
        prompt_instructions.append("\n**ä¾é ¼:**")
        prompt_instructions.append(
            f"ã“ã‚Œã‚‰ã®{media_type_name}ã®è§£æå†…å®¹ï¼ˆå…ƒã®å€¤ï¼‰ã¨å‡ºåŠ›ï¼ˆå„é …ç›®ï¼‰ã®é–¢ä¿‚æ€§ã‚’åˆ†æã—ã€"
            f"åŒæ§˜ã®{media_type_name}ãƒ•ã‚¡ã‚¤ãƒ«ã‚’å…¥åŠ›ã¨ã—ã¦ä¸ãˆãŸéš›ã«ã€ã“ã‚Œã‚‰ã®å‡ºåŠ›é …ç›®ï¼ˆ{field_list}ï¼‰ã‚’ç”Ÿæˆã•ã›ã‚‹ãŸã‚ã®"
            f"AIã«ä¸ãˆã‚‹ã¹ãæŒ‡ç¤ºï¼ˆãƒ—ãƒ­ãƒ³ãƒ—ãƒˆï¼‰ã‚’æ¨æ¸¬ã—ã€ä½œæˆã—ã¦ãã ã•ã„ã€‚"
        )
        prompt_instructions.append("\nç”Ÿæˆã™ã‚‹ãƒ—ãƒ­ãƒ³ãƒ—ãƒˆã®è¦ä»¶:")
        prompt_instructions.append(f"* {media_type_name}ãƒ•ã‚¡ã‚¤ãƒ«ã®å†…å®¹ã‚’è§£æã—ã¦æŒ‡å®šã•ã‚ŒãŸé …ç›®ã‚’æŠ½å‡ºã™ã‚‹æ±ç”¨çš„ãªæŒ‡ç¤ºã«ã—ã¦ãã ã•ã„ã€‚")
        prompt_instructions.append("* ãƒ—ãƒ­ãƒ³ãƒ—ãƒˆã¯ã€AIã«å¯¾ã™ã‚‹æŒ‡ç¤ºã¨ã—ã¦æ©Ÿèƒ½ã™ã‚‹ã€ç«¯çš„ã§çŸ­ã„æ–‡ç« ã«ã¾ã¨ã‚ã‚‹ã“ã¨ã€‚")
        prompt_instructions.append(f"* {media_type_name}è§£æã«ç‰¹åŒ–ã—ãŸæŒ‡ç¤ºå†…å®¹ã«ã—ã¦ãã ã•ã„ã€‚")
        
        # JSONå½¢å¼ã§å‡ºåŠ›ã•ã›ã‚‹æŒ‡ç¤º
        prompt_instructions.append("è¿”ç­”ã¯JSONå½¢å¼ã§ {\"prompt\": \"<ãƒ—ãƒ­ãƒ³ãƒ—ãƒˆ>\"} ã®ã¿ã‚’è¿”ã—ã€ä»–ã®æ–‡è¨€ã‚’å«ã‚ãªã„ã§ãã ã•ã„ã€‚")
        
        # AIã«é€ä¿¡ã™ã‚‹ãƒ—ãƒ­ãƒ³ãƒ—ãƒˆå…¨æ–‡ã‚’ãƒ­ã‚°å‡ºåŠ›
        prompt_content = "\n".join(prompt_instructions)
        logger.info(f"â˜…{media_type_name}ãƒ¢ãƒ¼ãƒ‰ç”¨aiã«é€ã£ãŸå…¨æ–‡ã ã‚ˆâ˜…\n{prompt_content}")
        
        try:
            logger.info(f"ğŸ¤– Generating {media_type_name} rule prompt via Gemini API...")
            rule_generation_start = time.time()
            resp = self.gemini.client.models.generate_content(
                model=self.gemini.transcription_model,
                contents=prompt_content
            )
            rule_generation_time = time.time() - rule_generation_start
            logger.info(f"â±ï¸ Rule prompt generation completed in {rule_generation_time:.2f} seconds")
            
            text = resp.text.strip()
            logger.debug(f"ğŸ“„ Raw response: {text[:100]}...")
            
            # ã‚³ãƒ¼ãƒ‰ãƒ–ãƒ­ãƒƒã‚¯é™¤å»ã¨JSONè§£æ
            if text.startswith("```"):
                text = re.sub(r"```(?:json)?\\n?", "", text)
                text = text.rstrip("`\\n ")
            
            start = text.find("{")
            end = text.rfind("}")
            json_str = text[start:end+1] if start != -1 and end != -1 else text
            
            try:
                data = json.loads(json_str)
                rule_prompt = data.get("prompt", "").strip()
                logger.info(f"âœ… Generated {media_type_name} rule prompt: {rule_prompt}")
                return rule_prompt
            except Exception as e:
                logger.error(f"âŒ {media_type_name}ãƒ—ãƒ­ãƒ³ãƒ—ãƒˆJSONãƒ‘ãƒ¼ã‚¹ã‚¨ãƒ©ãƒ¼: {e}, raw text: '{text}'")
                return ""
                
        except Exception as e:
            logger.error(f"âŒ {media_type_name}ãƒ—ãƒ­ãƒ³ãƒ—ãƒˆç”Ÿæˆã‚¨ãƒ©ãƒ¼: {e}")
            return ""

    async def create_rule(self, samples: List[Dict[str, Any]], mode: str = ProcessMode.NORMAL) -> Dict[str, Any]:
        """
        æ–°è¦ãƒ«ãƒ¼ãƒ«ã‚’AIã«ç”Ÿæˆã•ã›ã€ãƒ­ãƒ¼ã‚«ãƒ«ã«ä¿å­˜ (3ã‚¹ãƒ†ãƒƒãƒ—ï¼šprompt/jsonä¾‹/title)
        å¼•æ•° samples: [{"input": str, "output": Dict[str,str], "fields": List[str]}]
        å¼•æ•° mode: å‡¦ç†ãƒ¢ãƒ¼ãƒ‰ï¼ˆProcessModeå®šæ•°ï¼‰
        æˆ»ã‚Šå€¤: metadata dict (rule_name, etc.)
        """
        # --- å…¥åŠ›ã‚µãƒ³ãƒ—ãƒ«ã‚’ãƒ†ãƒ¼ãƒ–ãƒ«å½¢å¼ã§æ§‹ç¯‰ ---
        now = datetime.now().strftime("%Y-%m-%d %H:%M:%S")
        # fields ã«ç©ºæ–‡å­—ãŒå«ã¾ã‚Œã¦ã„ã‚‹å ´åˆã¯é™¤å¤–ã™ã‚‹
        fields = [f for f in samples[0].get('fields', []) if f] if samples else []
        headers_init = ["AIã®é€²æ—", "å…ƒã®å€¤"] + fields
        # AIã®é€²æ—æ¬„ã¯ç©ºæ–‡å­—ã¨ã—ã€ä¸Šéƒ¨ãƒ‘ãƒãƒ«ã§ã¯å€¤ã‚’è¡¨ç¤ºã—ãªã„
        rows_init = [["", s.get('input','')] + [s.get('output',{}).get(f,'') for f in fields] for s in samples]
        sample_data = {"headers": headers_init, "rows": rows_init}
        logger.debug(f"Generated sample_data: {sample_data}")

        # --- Phase1: å‹•çš„ãƒ—ãƒ­ãƒ³ãƒ—ãƒˆç”Ÿæˆï¼ˆãƒ¢ãƒ¼ãƒ‰åˆ¥å¯¾å¿œï¼‰ ---
        logger.info(f"Starting rule creation for mode: {mode}")
        
        if mode in [ProcessMode.IMAGE, ProcessMode.VIDEO, ProcessMode.AUDIO]:
            # ç”»åƒãƒ»å‹•ç”»ãƒ»éŸ³å£°ãƒ¢ãƒ¼ãƒ‰ã®å ´åˆï¼šå®Ÿéš›ã®ãƒ•ã‚¡ã‚¤ãƒ«å†…å®¹ã‚’è§£æã—ã¦ãƒ—ãƒ­ãƒ³ãƒ—ãƒˆç”Ÿæˆ
            logger.info(f"Processing {mode} mode rule creation with file analysis")
            rule_prompt = await self._generate_media_rule_prompt(samples, fields, mode)
        else:
            # ãƒ†ã‚­ã‚¹ãƒˆãƒ¢ãƒ¼ãƒ‰ã®å ´åˆï¼šå¾“æ¥ã®å‡¦ç†
            logger.info("Processing normal mode rule creation")
            rule_prompt = self._generate_text_rule_prompt(samples, fields)

        # --- Phase2: JSONãƒ•ã‚©ãƒ¼ãƒãƒƒãƒˆä¾‹ç”Ÿæˆ (Pythonã§å®Ÿè£…) ---
        logger.info("Generating json_format_example using _generate_json_example...")
        json_format_example = self._generate_json_example(sample_data)
        logger.debug(f"Generated json_format_example: {json_format_example}")

        # --- Phase3: ã‚¿ã‚¤ãƒˆãƒ«ç”Ÿæˆ ---
        title_instructions = [
            "æ¬¡ã®å‘½ä»¤æ–‡ã«ãµã•ã‚ã—ã„çŸ­ã„ãƒ«ãƒ¼ãƒ«åã‚’æ—¥æœ¬èªã§è¿”ã—ã¦ãã ã•ã„ã€‚",
            "è¿”ç­”ã¯ {\"rule_name\": \"<ãƒ«ãƒ¼ãƒ«å>\"} ã®å½¢å¼ã§ JSON ã®ã¿ã‚’è¿”ã—ã€ä»–ã®æ–‡è¨€ã‚’å«ã‚ãªã„ã§ãã ã•ã„ã€‚",
            f"å‘½ä»¤æ–‡: {rule_prompt}"
        ]
        # AIã«é€ä¿¡ã™ã‚‹ã‚¿ã‚¤ãƒˆãƒ«ç”Ÿæˆç”¨ãƒ—ãƒ­ãƒ³ãƒ—ãƒˆå…¨æ–‡ã‚’ãƒ­ã‚°å‡ºåŠ›ã™ã‚‹
        title_content = "\n".join(title_instructions)
        logger.info(f"â˜…aiã«é€ã£ãŸå…¨æ–‡ã ã‚ˆâ˜…\n{title_content}")
        logger.info("Generating rule title via Gemini API...")
        resp3 = self.gemini.client.models.generate_content(
            model=self.gemini.title_model,
            contents=title_content
        )
        # JSONãƒ‘ãƒ¼ã‚¹ã—ã¦ rule_name ã‚’å–å¾—
        text = resp3.text.strip()
        # ã‚³ãƒ¼ãƒ‰ãƒ–ãƒ­ãƒƒã‚¯ã‚„ãƒãƒƒã‚¯ã‚¯ã‚ªãƒ¼ãƒˆã‚’é™¤å»
        if text.startswith("```"):
            # ```json ã‚„ ``` ã‚³ãƒ¼ãƒ‰ãƒ–ãƒ­ãƒƒã‚¯ãƒãƒ¼ã‚«ãƒ¼ã‚’å‰Šé™¤
            text = re.sub(r"```(?:json)?\\n?", "", text)
            text = text.rstrip("`\\n ") # æœ«å°¾ã®ãƒãƒƒã‚¯ã‚¯ã‚ªãƒ¼ãƒˆã€æ”¹è¡Œã€ã‚¹ãƒšãƒ¼ã‚¹ã‚’å‰Šé™¤
        # JSONéƒ¨åˆ†ã‚’æŠ½å‡º
        start = text.find("{")
        end = text.rfind("}")
        json_str = text[start:end+1] if start != -1 and end != -1 else text
        try:
            data = json.loads(json_str)
            rule_name = data.get("rule_name", "").strip()
        except json.JSONDecodeError:
            logger.warning("ãƒ«ãƒ¼ãƒ«åç”Ÿæˆãƒ¬ã‚¹ãƒãƒ³ã‚¹ã®JSONè§£æã«å¤±æ•—")
            rule_name = f"ãƒ«ãƒ¼ãƒ«_{now}"
        if not rule_name:
            rule_name = f"ãƒ«ãƒ¼ãƒ«_{now}"
        logger.info(f"Generated rule title: {rule_name}")

        # --- æ–°è¦ãƒ«ãƒ¼ãƒ«ã‚’ä¿å­˜ ---
        # æ–°ã—ã„IDã‚’ç”Ÿæˆï¼ˆæ—¢å­˜ã®æœ€å¤§å€¤+1ï¼‰
        max_id = max([r.get("id", 0) for r in self._rules], default=0)
        new_id = max_id + 1

        new_rule = {
            "title": rule_name,
            "prompt": rule_prompt,
            "json_format_example": json_format_example,
            "sample_data": sample_data,
            "mode": mode,
            "id": new_id,
            "rule_name": rule_name  # UIå´ã®äº’æ›æ€§ã®ãŸã‚
        }
        
        self._rules.append(new_rule)
        logger.info(f"Assigned id={new_id} to new rule '{rule_name}' with mode={mode}")
        self._save_rules()
        logger.info(f"Rule id={new_id} ('{rule_name}') created and saved with mode={mode}.")
        return new_rule

    async def regenerate_rule(self, rule_id: int, samples: List[Dict[str, Any]], mode: str = None) -> Dict[str, Any]:
        """
        æ—¢å­˜ãƒ«ãƒ¼ãƒ«ã‚’å†ç”Ÿæˆã—ã€æ›´æ–°ã™ã‚‹
        """
        # æŒ‡å®šãƒ«ãƒ¼ãƒ«ã‚’æ¤œç´¢
        updated_idx = -1
        old_mode = ProcessMode.NORMAL  # ãƒ‡ãƒ•ã‚©ãƒ«ãƒˆå€¤
        for idx, r in enumerate(self._rules):
            if r.get("id") == rule_id:
                updated_idx = idx
                old_mode = r.get("mode", ProcessMode.NORMAL)  # æ—¢å­˜ã®ãƒ¢ãƒ¼ãƒ‰ã‚’ä¿æŒ
                break
        if updated_idx == -1:
            raise GeminiAPIError(f"ãƒ«ãƒ¼ãƒ« id={rule_id} ãŒè¦‹ã¤ã‹ã‚Šã¾ã›ã‚“")

        # ãƒ¢ãƒ¼ãƒ‰ãŒæŒ‡å®šã•ã‚Œã¦ã„ãªã„å ´åˆã¯æ—¢å­˜ã®ãƒ¢ãƒ¼ãƒ‰ã‚’ä½¿ç”¨
        if mode is None:
            mode = old_mode

        # è¿½åŠ : regenerate_ruleé–‹å§‹æ™‚ã®ãƒ‡ãƒãƒƒã‚°ãƒ­ã‚°
        logger.debug(f"Starting regenerate_rule: rule_id={rule_id}, updated_idx={updated_idx}, current_ids={[r.get('id') for r in self._rules]}")
        logger.info(f"Regenerating rule id={rule_id} with mode={mode}...")
        # æ–°ã—ã„ã‚µãƒ³ãƒ—ãƒ«ãƒ‡ãƒ¼ã‚¿ã§ãƒ«ãƒ¼ãƒ«ã‚’ä½œæˆ (create_ruleã‚’å‘¼ã³å‡ºã™)
        try:
            new_rule_metadata = await self.create_rule(samples, mode)
            # è¿½åŠ : create_ruleå¾Œã®ãƒ‡ãƒãƒƒã‚°ãƒ­ã‚°
            logger.debug(f"After create_rule: metadata returned={new_rule_metadata}")
            logger.debug(f"Current rule IDs after create: {[r.get('id') for r in self._rules]}")

            if 0 <= updated_idx < len(self._rules) -1: # æœ«å°¾ã«è¿½åŠ ã•ã‚ŒãŸã®ã§ã€ãã‚Œã‚ˆã‚Šå‰ã«ã‚ã‚‹ã¯ãš
                 # è¿½åŠ : å¤ã„ãƒ«ãƒ¼ãƒ«å‰Šé™¤å‰ã®ãƒ‡ãƒãƒƒã‚°ãƒ­ã‚°
                 logger.debug(f"Deleting old rule at index={updated_idx}, id={rule_id}")
                 del self._rules[updated_idx]
                 # è¿½åŠ : å¤ã„ãƒ«ãƒ¼ãƒ«å‰Šé™¤å¾Œã®ãƒ‡ãƒãƒƒã‚°ãƒ­ã‚°
                 logger.debug(f"Rule IDs after deletion: {[r.get('id') for r in self._rules]}")
                 self._save_rules()  # å‰Šé™¤å¾Œã«å†åº¦ä¿å­˜
                 logger.info(f"Old rule id={rule_id} removed after regeneration.")
                 return new_rule_metadata  # æ–°ã—ã„ãƒ«ãƒ¼ãƒ«ã®ãƒ¡ã‚¿ãƒ‡ãƒ¼ã‚¿ã‚’è¿”ã™
            else:
                 # è¿½åŠ : æƒ³å®šå¤–ãƒ‘ã‚¹æ™‚ã®ãƒ‡ãƒãƒƒã‚°ãƒ­ã‚°
                 logger.warning(f"Could not delete old rule id={rule_id}, unexpected updated_idx={updated_idx} with current length={len(self._rules)}")
                 logger.debug(f"Rules remain unchanged: {[r.get('id') for r in self._rules]}")
                 self._save_rules()  # å¿µã®ãŸã‚ä¿å­˜
                 return new_rule_metadata

        except Exception as e:
            logger.error(f"Error regenerating rule id={rule_id}: {e}")
            # å†ç”Ÿæˆã«å¤±æ•—ã—ãŸå ´åˆã€å…ƒã®ãƒ«ãƒ¼ãƒ«ã¯ãã®ã¾ã¾æ®‹ã‚‹
            raise GeminiAPIError(f"ãƒ«ãƒ¼ãƒ« id={rule_id} ã®å†ç”Ÿæˆã«å¤±æ•—ã—ã¾ã—ãŸ: {e}")


    def get_rules(self, mode: str = None) -> List[Dict[str, Any]]:
        """
        ä¿å­˜æ¸ˆã¿ãƒ«ãƒ¼ãƒ«ã®ãƒ¡ã‚¿æƒ…å ±ãƒªã‚¹ãƒˆã‚’è¿”å´
        å¼•æ•° mode: æŒ‡å®šã•ã‚Œã¦ã„ã‚‹å ´åˆã¯ã€ãã®ãƒ¢ãƒ¼ãƒ‰ã®ãƒ«ãƒ¼ãƒ«ã®ã¿ã‚’è¿”å´
        """
        # ãƒ­ãƒ¼ã‚«ãƒ«ãƒ•ã‚¡ã‚¤ãƒ«ã‹ã‚‰æœ€æ–°ã®çŠ¶æ…‹ã‚’èª­ã¿è¾¼ã‚€ï¼ˆä»–ã®ãƒ—ãƒ­ã‚»ã‚¹ã«ã‚ˆã‚‹å¤‰æ›´ã‚’åæ˜ ã™ã‚‹ãŸã‚ï¼‰
        # self._load_rules()
        # â†‘UIã‹ã‚‰é »ç¹ã«å‘¼ã°ã‚Œã‚‹å¯èƒ½æ€§ãŒã‚ã‚‹ãŸã‚ã€æ¯å›ãƒ­ãƒ¼ãƒ‰ã™ã‚‹ã®ã¯åŠ¹ç‡ãŒæ‚ªã„ã€‚
        # ä¿å­˜æ™‚ã«åŒæœŸãŒå–ã‚Œã¦ã„ã‚‹å‰æã¨ã™ã‚‹ã€‚å¿…è¦ã§ã‚ã‚Œã°UIå´ã§ãƒªãƒ•ãƒ¬ãƒƒã‚·ãƒ¥ã‚’ä¿ƒã™ã€‚
        
        if mode is None:
            return self._rules
        else:
            # æŒ‡å®šã•ã‚ŒãŸãƒ¢ãƒ¼ãƒ‰ã®ãƒ«ãƒ¼ãƒ«ã®ã¿ã‚’è¿”å´
            filtered_rules = [rule for rule in self._rules if rule.get("mode", ProcessMode.NORMAL) == mode]
            logger.debug(f"Filtered rules for mode={mode}: {len(filtered_rules)} out of {len(self._rules)} total rules")
            return filtered_rules

    def delete_rule(self, rule_id: int) -> bool:
        """
        æŒ‡å®šã—ãŸrule_idã®ãƒ«ãƒ¼ãƒ«ã‚’å‰Šé™¤ã™ã‚‹
        æˆåŠŸæ™‚ã«Trueã€å¤±æ•—æ™‚ã«Falseã‚’è¿”å´
        """
        initial_length = len(self._rules)
        self._rules = [r for r in self._rules if r.get("id") != rule_id]
        if len(self._rules) < initial_length:
            self._save_rules()
            logger.info(f"Rule id={rule_id} deleted successfully.")
            return True
        else:
            logger.warning(f"å‰Šé™¤å¯¾è±¡ã®ãƒ«ãƒ¼ãƒ« id={rule_id} ãŒè¦‹ã¤ã‹ã‚Šã¾ã›ã‚“ã§ã—ãŸ")
            return False


    async def apply_rule(self, rule_id: int, inputs: List[str]) -> List[Dict[str, Any]]:
        """
        æŒ‡å®šã—ãŸãƒ«ãƒ¼ãƒ«ã‚’å…¥åŠ›ãƒªã‚¹ãƒˆã«é©ç”¨ã—ã€çµæœã‚’è¿”å´
        (æ³¨: ç¾åœ¨ã®å®Ÿè£…ã¯ã‚µãƒ³ãƒ—ãƒ«ãƒ‡ãƒ¼ã‚¿ã¨ã®å®Œå…¨ä¸€è‡´ã®ã¿ã€‚å°†æ¥çš„ã«ã¯AIé©ç”¨ãŒå¿…è¦)
        """
        # ãƒ«ãƒ¼ãƒ«ã‚’æ¤œç´¢
        rule = next((r for r in self._rules if r.get("id") == rule_id), None)
        if not rule:
            raise GeminiAPIError(f"ãƒ«ãƒ¼ãƒ« id={rule_id} ãŒè¦‹ã¤ã‹ã‚Šã¾ã›ã‚“")

        sample_data = rule.get('sample_data', {})
        headers = sample_data.get('headers', [])
        rows = sample_data.get('rows', [])
        results = []
        rule_mode = rule.get('mode', ProcessMode.NORMAL)  # ãƒ«ãƒ¼ãƒ«ã®ãƒ¢ãƒ¼ãƒ‰ã‚’å–å¾—

        if not headers or not rows:
             logger.warning(f"Rule id={rule_id} has empty sample_data. Cannot apply rule based on samples.")
             # ã‚µãƒ³ãƒ—ãƒ«ãŒãªã„å ´åˆã€å…¨å…¥åŠ›ã«å¯¾ã—ã¦ã‚¨ãƒ©ãƒ¼ã‚’è¿”ã™
             return [{"input": inp, "output": {}, "status": "error", "error_msg": "ãƒ«ãƒ¼ãƒ«ã«ã‚µãƒ³ãƒ—ãƒ«ãƒ‡ãƒ¼ã‚¿ãŒã‚ã‚Šã¾ã›ã‚“"} for inp in inputs]

        # å‡ºåŠ›ãƒ˜ãƒƒãƒ€ãƒ¼ã®ã‚¤ãƒ³ãƒ‡ãƒƒã‚¯ã‚¹ã‚’å–å¾— (3åˆ—ç›®ä»¥é™)
        output_indices = [idx for idx, h in enumerate(headers, start=1) if idx >= 3 and h.strip()]
        output_headers = [headers[i-1] for i in output_indices]
        # ãƒ­ã‚°: å‡¦ç†é–‹å§‹
        logger.info(f"apply_rule é–‹å§‹: rule_id={rule_id} mode={rule_mode} å¯¾è±¡è¡Œæ•°={len(inputs)}ä»¶")

        logger.info(f"Applying rule id={rule_id} based on sample matching...")
        for inp in inputs:
            # ãƒãƒƒãƒã™ã‚‹ã‚µãƒ³ãƒ—ãƒ«è¡Œã‚’æ¤œç´¢ (2åˆ—ç›®ãŒå…¥åŠ›å€¤ã¨ä¸€è‡´ã™ã‚‹ã‹)
            match = next((row for row in rows if len(row) > 1 and row[1] == inp), None)
            if match:
                try:
                    # å‡ºåŠ›ãƒ•ã‚£ãƒ¼ãƒ«ãƒ‰ç”Ÿæˆ
                    out = {}
                    for idx, key in zip(output_indices, output_headers):
                         if idx -1 < len(match): # è¡Œã®é•·ã•ãƒã‚§ãƒƒã‚¯
                             out[key] = match[idx - 1]
                         else:
                             logger.warning(f"Index {idx-1} out of bounds for matched row in rule id={rule_id} for input '{inp}'. Header: '{key}'")
                             out[key] = "" # ã‚¤ãƒ³ãƒ‡ãƒƒã‚¯ã‚¹å¤–ã®å ´åˆã¯ç©ºæ–‡å­—

                    results.append({"input": inp, "output": out, "status": "success"})
                    logger.debug(f"Input '{inp}' matched sample. Output: {out}")
                except Exception as e:
                     logger.error(f"Error processing matched row for input '{inp}' in rule id={rule_id}: {e}")
                     results.append({"input": inp, "output": {}, "status": "error", "error_msg": f"ã‚µãƒ³ãƒ—ãƒ«å‡¦ç†ä¸­ã«ã‚¨ãƒ©ãƒ¼ç™ºç”Ÿ: {e}"})

            else:
                logger.debug(f"Input '{inp}' did not match any sample in rule id={rule_id}, calling AI.")
                # ã‚µãƒ³ãƒ—ãƒ«ä¸€è‡´ã—ãªã„å ´åˆã¯AIã‚’å‘¼ã³å‡ºã—ã¦å‡¦ç†
                try:
                    # ãƒ¢ãƒ¼ãƒ‰ã«å¿œã˜ã¦å‡¦ç†æ–¹æ³•ã‚’å¤‰æ›´
                    if rule_mode in [ProcessMode.IMAGE, ProcessMode.VIDEO, ProcessMode.AUDIO]:
                        # ç”»åƒãƒ»å‹•ç”»ãƒ»éŸ³å£°ã®å ´åˆã¯ãƒ¡ãƒ‡ã‚£ã‚¢è§£æAPIã‚’ä½¿ç”¨
                        logger.info(f"Processing {rule_mode} file: {inp}")
                        
                        # ãƒ•ã‚¡ã‚¤ãƒ«ãƒ‘ã‚¹ã®æ¤œè¨¼
                        file_path = Path(inp)
                        if not file_path.exists():
                            raise FileNotFoundError(f"ãƒ•ã‚¡ã‚¤ãƒ«ãŒè¦‹ã¤ã‹ã‚Šã¾ã›ã‚“: {inp}")
                        
                        # ãƒ—ãƒ­ãƒ³ãƒ—ãƒˆã®çµ„ã¿ç«‹ã¦
                        media_prompt = f"{rule.get('prompt', '')}\n\nä»¥ä¸‹ã®é …ç›®ã«ã¤ã„ã¦å›ç­”ã—ã¦ãã ã•ã„:\n"
                        for header in output_headers:
                            media_prompt += f"- {header}\n"
                        media_prompt += f"\nå›ç­”ã¯ä»¥ä¸‹ã®JSONãƒ•ã‚©ãƒ¼ãƒãƒƒãƒˆã§è¿”ã—ã¦ãã ã•ã„:\n"
                        media_prompt += json.dumps(rule.get("json_format_example", {}), ensure_ascii=False, indent=2)
                        
                        # ç”»åƒãƒ»å‹•ç”»ãƒ»éŸ³å£°è§£æAPIã‚’å‘¼ã³å‡ºã—ï¼ˆéåŒæœŸï¼‰
                        logger.debug(f"ãƒ¡ãƒ‡ã‚£ã‚¢è§£æãƒ—ãƒ­ãƒ³ãƒ—ãƒˆ:\n{media_prompt}")
                        if rule_mode == ProcessMode.IMAGE:
                            ai_response = await self.gemini.analyze_image(inp, media_prompt)
                        elif rule_mode == ProcessMode.VIDEO:
                            ai_response = await self.gemini.analyze_video(inp, media_prompt)
                        else:  # AUDIO
                            ai_response = await self.gemini.analyze_audio(inp, media_prompt)
                        
                        # ãƒ¬ã‚¹ãƒãƒ³ã‚¹ã‚’JSONè§£æ
                        text = ai_response.strip()
                        # ã‚³ãƒ¼ãƒ‰ãƒ–ãƒ­ãƒƒã‚¯ãƒãƒ¼ã‚«ãƒ¼é™¤å»
                        if text.startswith("```"):
                            text = re.sub(r"```(?:json)?\n?", "", text)
                            text = text.rstrip("`\n ")
                        # JSONéƒ¨åˆ†æŠ½å‡º
                        start = text.find("{")
                        end = text.rfind("}")
                        json_str = text[start:end+1] if start != -1 and end != -1 else text
                        data = json.loads(json_str)
                        out = {key: data.get(key, "") for key in output_headers}
                        
                        results.append({"input": inp, "output": out, "status": "success"})
                        logger.debug(f"Media analysis output for input '{inp}': {out}")
                        
                    else:
                        # ãƒ†ã‚­ã‚¹ãƒˆãƒ¢ãƒ¼ãƒ‰ã®å ´åˆã¯å¾“æ¥ã®å‡¦ç†
                        # ãƒ—ãƒ­ãƒ³ãƒ—ãƒˆã®çµ„ã¿ç«‹ã¦
                        lines = [
                            rule.get("prompt", ""),
                            "æ¬¡ã®ã‚ˆã†ãªJSONãƒ•ã‚©ãƒ¼ãƒãƒƒãƒˆã§è¿”ç­”ã—ã¦ãã ã•ã„ã€‚",
                            json.dumps(rule.get("json_format_example", {}), ensure_ascii=False, indent=2),
                            f"å…ƒã®å€¤: {inp}"
                        ]
                        combined_prompt = "\n".join(lines)
                        # é€ä¿¡ãƒ—ãƒ­ãƒ³ãƒ—ãƒˆã‚’ãƒ­ã‚°ã«å‡ºåŠ›
                        logger.debug(f"é€ä¿¡ãƒ—ãƒ­ãƒ³ãƒ—ãƒˆå†…å®¹:\n{combined_prompt}")
                        logger.info(f"ãƒªã‚¢ãƒ«ãƒ‡ãƒ¼ã‚¿å¤‰æ›ç”¨ãƒ¢ãƒ‡ãƒ«: {self.gemini.minutes_model} ã‚’ä½¿ç”¨ã—ã¦AIå‘¼ã³å‡ºã—ã‚’å®Ÿè¡Œ")
                        resp = self.gemini.client.models.generate_content(
                            model=self.gemini.minutes_model,
                            contents=combined_prompt
                        )
                        text = resp.text.strip()
                        # ã‚³ãƒ¼ãƒ‰ãƒ–ãƒ­ãƒƒã‚¯ãƒãƒ¼ã‚«ãƒ¼é™¤å»
                        if text.startswith("```"):
                            text = re.sub(r"```(?:json)?\n?", "", text)
                            text = text.rstrip("`\n ")
                        # JSONéƒ¨åˆ†æŠ½å‡º
                        start = text.find("{")
                        end = text.rfind("}")
                        json_str = text[start:end+1] if start != -1 and end != -1 else text
                        data = json.loads(json_str)
                        out = {key: data.get(key, "") for key in output_headers}
                        results.append({"input": inp, "output": out, "status": "success"})
                        logger.debug(f"AI output for input '{inp}': {out}")
                        
                except Exception as e:
                    logger.error(f"AIå‡¦ç†ã‚¨ãƒ©ãƒ¼ for input '{inp}': {e}")
                    results.append({"input": inp, "output": {}, "status": "error", "error_msg": str(e)})

        # ãƒ­ã‚°: å‡¦ç†å®Œäº†
        success_count = sum(1 for r in results if r.get("status") == "success")
        error_count = len(results) - success_count
        logger.info(f"apply_rule å®Œäº†: success={success_count}ä»¶ error={error_count}ä»¶")
        return results

    def update_rule(self, rule_id: int, new_data: Dict[str, Any]) -> bool:
        """æ—¢å­˜ãƒ«ãƒ¼ãƒ«ã®titleã€promptã€modeã‚’æ›´æ–°ã—ä¿å­˜ã™ã‚‹"""
        logger.info(f"Updating rule id={rule_id} with data={new_data}")
        for r in self._rules:
            if r.get("id") == rule_id:
                r["title"] = new_data.get("title", r["title"])
                r["prompt"] = new_data.get("prompt", r["prompt"])
                if "mode" in new_data:
                    r["mode"] = new_data["mode"]
                    logger.info(f"Rule id={rule_id} mode updated to {new_data['mode']}")
                self._save_rules()
                logger.info(f"Rule id={rule_id} updated successfully.")
                return True
        logger.warning(f"Rule id={rule_id} not found for update.")
        return False 